The pretrained model that I used is from here [TensorLayerX implementaion of SRGAN](https://github.com/tensorlayer/srgan)

I'm sorry I had to use a pre-trained model to do this project. If I had planned correctly and worked on this project sooner, I would have changed the topic. I really wanted to be able to train it myself. So in my progress report, I mentioned wanting to create new wallpapers. The plan was to train the model using only blue or blue scaled images and then give it magenta backgrounds I find online and it would create this amazing blue and magenta wallpaper. Assuming that I could fool it in that way. I also wanted to train a model with only animals with fur and then input humans and possibly create deranged-looking apes. But I was not able to because I would get an error saying my GPU ran out of memory. I looked for solutions online, and they said to reduce the batch-size. I decreased all the way to 1 and it still was too much. So I gave up on trying to train my own and just used a pre-trained one. I decided to not do the presentation because of this. I was not going to up and say I read a research paper, implemented the model they created, and did nothing else with it. That is just a waste of people's time. I would have loved to show the experiments with training because I genuinely thought this technology was super cool. It is able to generate higher resolution images using the images it was trained with which may havecreated textures different from the original. But it still looked like a real image if you never saw the original. It gets better at doing this as it has more training data. So if I limit the training data, I could have theoretically trained it with specific textures it will try to apply and make some cool images to share.
